{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFYMLutOEjUZ"
   },
   "source": [
    "<h1 align=center><font size = 4>HW4: k-NN, Bayes classifier, PCA and GMM</font></h1> \n",
    "<h2 align=center><font size = 3>【Machine Learning Course】</font></h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWeONzMVE2l3"
   },
   "source": [
    "- This is an individual assignment. However, you are allowed to discuss the problems with other students in the class. But you should write your own code and report.\n",
    "- If you have any discussion with others, you should acknowledge the discussion in your report by mentioning their names.\n",
    "- You should submit two files, one pdf file with report (<your-student-ID>.pdf) and one code file with all your code (code.ipynb).\n",
    "- You are free to use libraries such as matplotlib, numpy, scipy and sklearn for python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpO3HpkkASUH"
   },
   "source": [
    "\n",
    "## **问题一：k近邻和最优贝叶斯分类器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msfm1Ewy_3UA"
   },
   "source": [
    "### 步骤1 引入必要的库\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ne0ojnev_ECB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHKbSAfsAfmv"
   },
   "source": [
    "### 步骤2 数据集生成(1-a)\n",
    "\n",
    "实现函数(X,y)=data_gen(n,d,sigma,w,b)，并调用函数生成合成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nGv_NwBv_TDQ"
   },
   "outputs": [],
   "source": [
    "def data_gen(n, d, sigma, w, b):\n",
    "    np.random.seed(0)\n",
    "    x = np.random.rand(n, d) * 2 - 1\n",
    "    np.random.seed(0)\n",
    "    u = np.random.rand(n, 1)\n",
    "    s=1/(1+np.exp(-((np.matmul(x, w)+b)/sigma)))\n",
    "    \n",
    "    y = np.ones((n, 1))\n",
    "    y[s>=u] = 1\n",
    "    y[s<u] = -1\n",
    "    return x, y\n",
    "\n",
    "\n",
    "n = 6000\n",
    "d=10\n",
    "sigma=1\n",
    "w = np.zeros((d, 1))\n",
    "w[0, 0] = 1\n",
    "b=0\n",
    "x, y = data_gen(n, d, sigma, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWHrqQgzA9q-"
   },
   "source": [
    "### 步骤3 贝叶斯分类器(1-b)\n",
    "实现函数error=Bayes(X,y,w,b)，并调用函数得到贝叶斯分类器在该合成数据集上的错误率 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UYdm3iNFBfWV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error为： 0.37566666666666665\n"
     ]
    }
   ],
   "source": [
    "def Bayes(X,y,w,b):\n",
    "    predict = np.matmul(X, w)+b\n",
    "    predict[predict>=0] = 1\n",
    "    predict[predict<0] = -1\n",
    "    error = np.sum(predict != y)/X.shape[0]\n",
    "    return error\n",
    "\n",
    "error = Bayes(x, y, w, b)\n",
    "print('error为：', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  10000 时error为： 0.3767\n",
      "n =  20000 时error为： 0.376\n",
      "n =  30000 时error为： 0.3791\n",
      "n =  40000 时error为： 0.3808\n",
      "n =  50000 时error为： 0.3784\n",
      "n =  60000 时error为： 0.38021666666666665\n",
      "n =  70000 时error为： 0.3825\n",
      "n =  80000 时error为： 0.3784\n",
      "n =  90000 时error为： 0.3774777777777778\n",
      "n =  100000 时error为： 0.37894\n"
     ]
    }
   ],
   "source": [
    "for n in range(10000,100001,10000):\n",
    "    x, y = data_gen(n, d, sigma, w, b)\n",
    "    error = Bayes(x, y, w, b)\n",
    "    print('n = ', n, '时error为：', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  1000 时error为： 0.405\n",
      "n =  1500 时error为： 0.4026666666666667\n",
      "n =  2000 时error为： 0.3485\n",
      "n =  2500 时error为： 0.3788\n",
      "n =  3000 时error为： 0.386\n",
      "n =  3500 时error为： 0.3648571428571429\n",
      "n =  4000 时error为： 0.3725\n",
      "n =  4500 时error为： 0.37333333333333335\n",
      "n =  5000 时error为： 0.3806\n",
      "n =  5500 时error为： 0.37472727272727274\n",
      "n =  6000 时error为： 0.373\n"
     ]
    }
   ],
   "source": [
    "for n in range(1000,6001,500):\n",
    "    x, y = data_gen(n, d, sigma, w, b)\n",
    "    error = Bayes(x, y, w, b)\n",
    "    print('n = ', n, '时error为：', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma =  0.01 时error为： 0.00738\n",
      "sigma =  0.1 时error为： 0.06964\n",
      "sigma =  1 时error为： 0.37897\n",
      "sigma =  10 时error为： 0.48798\n"
     ]
    }
   ],
   "source": [
    "sig = [0.01,0.1,1,10]\n",
    "n = 1000000\n",
    "for sig in sig:\n",
    "    x, y = data_gen(n, d, sig, w, b)\n",
    "    error = Bayes(x, y, w, b)\n",
    "    print('sigma = ', sig, '时error为：', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIYN-Uz8Bftd"
   },
   "source": [
    "### 步骤4 k近邻分类器，L2距离 (1-d)\n",
    "实现函数(testYhat,error)=knn(trainX,trainY,textX,k,dist,testY)。利用步骤2中函数产生测试数据集，调用knn函数得到k近邻分类器在测试数据集上的错误率，此时使用L2距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "homTam4pCOWr"
   },
   "outputs": [],
   "source": [
    "def knn(trainX, trainY, testX, k, dist, testY):\n",
    "    if dist == 'l1':\n",
    "        p = 1\n",
    "    elif dist == 'l2':\n",
    "        p = 2\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k, p=p)\n",
    "    neigh.fit(trainX,trainY)\n",
    "    predict = neigh.predict(testX)\n",
    "    error = np.sum(predict != testY) / testY.shape[0]\n",
    "    return error\n",
    "\n",
    "n = 6000\n",
    "d=10\n",
    "sigma=1\n",
    "w = np.zeros((d, 1))\n",
    "w[0, 0] = 1\n",
    "b=0\n",
    "trainx, trainy = data_gen(n, d, sigma, w, b)\n",
    "testx, testy = data_gen(n, d, sigma, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当k取1时的错误率为: 0.4666666666666667\n",
      "当k取3时的错误率为: 0.4578333333333333\n",
      "当k取5时的错误率为: 0.44183333333333336\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 3, 5]:\n",
    "    error = knn(trainx, trainy.reshape(-1), testx, k, 'l2', testy.reshape(-1))\n",
    "    print('当k取'+str(k)+'时的错误率为:', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VhS6xOXCcPE"
   },
   "source": [
    "### 步骤5 k近邻分类器，L1距离 (1-e)\n",
    "利用步骤4中的数据集，重复步骤4，但使用L1距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PpFTfMfhCsTL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当k取1时的错误率为: 0.4645\n",
      "当k取3时的错误率为: 0.45916666666666667\n",
      "当k取5时的错误率为: 0.45566666666666666\n"
     ]
    }
   ],
   "source": [
    "n = 6000\n",
    "d=10\n",
    "sigma=1\n",
    "w = np.zeros((d, 1))\n",
    "w[0, 0] = 1\n",
    "b=0\n",
    "trainx, trainy = data_gen(n, d, sigma, w, b)\n",
    "testx, testy = data_gen(n, d, sigma, w, b)\n",
    "\n",
    "for k in [1, 3, 5]:\n",
    "    error = knn(trainx, trainy.reshape(-1), testx, k, 'l1', testy.reshape(-1))\n",
    "    print('当k取'+str(k)+'时的错误率为:', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL5LCl3CCsqD"
   },
   "source": [
    "### 步骤6 k近邻分类器，改变数据集且k=1 (1-f)\n",
    "设置sigma=0.01,0.1,10，重新生成训练和测试数据集。计算k近邻分类器(k=1)在测试集上的分类错误率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nqjaW5n_DSuK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma为0.01时的错误率为: 0.1145\n",
      "sigma为0.1时的错误率为: 0.15266666666666667\n",
      "sigma为1时的错误率为: 0.4655\n",
      "sigma为10时的错误率为: 0.49916666666666665\n"
     ]
    }
   ],
   "source": [
    "n = 6000\n",
    "d=10\n",
    "w = np.zeros((d, 1))\n",
    "w[0, 0] = 1\n",
    "b=0\n",
    "\n",
    "for sigma in [0.01, 0.1, 1, 10]:\n",
    "    trainx, trainy = data_gen(n, d, sigma, w, b)\n",
    "    testx, testy = data_gen(n, d, sigma, w, b)\n",
    "    error = knn(trainx, trainy.reshape(-1), testx, 1, 'l2', testy.reshape(-1))\n",
    "    print('sigma为'+str(sigma)+'时的错误率为:', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzVTlxIRDWci"
   },
   "source": [
    "\n",
    "## **问题2：PCA及GMM的应用**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWshhm9LDbji"
   },
   "source": [
    "### 步骤1 引入必要的库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v9XNHAbGDftS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_-sbVdcDgai"
   },
   "source": [
    "### 步骤2 MNIST数据集加载及预处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M_CiDgXYDsuC"
   },
   "outputs": [],
   "source": [
    "train_csv_data = pd.read_csv('mnist_train.csv')\n",
    "test_csv_data = pd.read_csv('mnist_test.csv')\n",
    "train_data = np.array(train_csv_data)\n",
    "test_data = np.array(test_csv_data)\n",
    "trainx = train_data[:, 1:]/255\n",
    "trainy = train_data[:, 0]\n",
    "testx = test_data[:, 1:]/255\n",
    "testy = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdX1zNE3DtGS"
   },
   "source": [
    "### 步骤3 GMM建模(2-a)\n",
    "利用GMM和训练数据集，对p(X=x|Y=c)进行建模，并利用建模的结果计算该模型在MNIST测试集上的错误率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cLF41PuBD7KC"
   },
   "outputs": [],
   "source": [
    "class_indexs = []\n",
    "class_prs = []\n",
    "for i in range(10):\n",
    "    class_indexs.append(np.where(trainy==i))\n",
    "    class_prs.append(np.where(trainy==i)[0].shape[0])\n",
    "\n",
    "models = []\n",
    "for i in range(10):\n",
    "    gmm = GaussianMixture(n_components=5, random_state=0).fit(trainx[class_indexs[i]])\n",
    "    models.append(gmm)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误率为： 0.1132\n"
     ]
    }
   ],
   "source": [
    "predict = []\n",
    "for i in range(testx.shape[0]):\n",
    "    score = []\n",
    "    for j in range(10):\n",
    "        score.append(np.max(models[j].predict_proba(testx[i].reshape(1, -1))[0])*class_prs[j])\n",
    "    predict.append(score.index(max(score)))\n",
    "predict = np.array(predict)\n",
    "error = np.sum(predict==testy)/testy.shape[0]\n",
    "print('错误率为：', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1BfwF_1D8Mi"
   },
   "source": [
    "### 步骤4 PCA+GMM(2-b)\n",
    "尝试先利用PCA降维后，再重复步骤3。计算模型在MNIST测试集上的错误率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fLD9HSpsEd9h"
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(trainx)\n",
    "ratio = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主成分个数为 34 方差和占比 0.7554978600486829\n",
      "主成分个数为 44 方差和占比 0.8032907553836797\n",
      "主成分个数为 59 方差和占比 0.850187763928468\n",
      "主成分个数为 87 方差和占比 0.9001062226425084\n",
      "主成分个数为 154 方差和占比 0.9501960192613031\n",
      "主成分个数为 331 方差和占比 0.9900129426354093\n"
     ]
    }
   ],
   "source": [
    "sum_ratio = []\n",
    "sum_r = 0\n",
    "for i in range(len(ratio)):\n",
    "    sum_r += ratio[i]\n",
    "    sum_ratio.append(sum_r)\n",
    "components_list = []\n",
    "#寻找方差比和为下列数据的主成分个数\n",
    "for r in [0.75, 0.8, 0.85, 0.9, 0.95, 0.99]:\n",
    "    for i in range(len(sum_ratio)):\n",
    "        if sum_ratio[i]>=r:\n",
    "            components_list.append(i+1)\n",
    "            print('主成分个数为',(i+1), '方差和占比', sum_ratio[i])\n",
    "            break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0274\n",
      "0.0268\n",
      "0.0297\n",
      "0.0368\n",
      "0.0493\n",
      "0.0836\n"
     ]
    }
   ],
   "source": [
    "for n in components_list:\n",
    "    pca = PCA(n_components = n)\n",
    "    pca.fit(trainx)\n",
    "    x_train_new = pca.transform(trainx)\n",
    "    x_test_new = pca.transform(testx)\n",
    "    x_train_class_new = []\n",
    "    for i in range(10):\n",
    "        x_train_class_new.append(x_train_new[trainy==i])\n",
    "    model = []\n",
    "    for x in x_train_class_new:\n",
    "        gmm = GaussianMixture(n_components = 5, random_state = 0, max_iter = 500)\n",
    "        gmm.fit(x)\n",
    "        model.append(gmm)\n",
    "    #计算log(density)\n",
    "    log_density = []\n",
    "    for GMM in model:\n",
    "        log_density.append(GMM.score_samples(x_test_new))\n",
    "    log_density = np.array(log_density)\n",
    "    #计算log_p_hat\n",
    "    log_P_hat = []\n",
    "    for i in range(10):\n",
    "        log_P_hat.append(np.log(class_prs[i])+log_density[i])\n",
    "    log_P_hat = np.array(log_P_hat)\n",
    "    count_err = 0\n",
    "    for i in range(testy.shape[0]):\n",
    "        if(log_P_hat[:,i].argmax() != testy[i]):\n",
    "            count_err += 1\n",
    "    error = count_err / testy.shape[0]\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主成分个数34: 错误率0.027300\n",
      "主成分个数35: 错误率0.026600\n",
      "主成分个数36: 错误率0.027500\n",
      "主成分个数37: 错误率0.027800\n",
      "主成分个数38: 错误率0.028300\n",
      "主成分个数39: 错误率0.028200\n",
      "主成分个数40: 错误率0.026600\n",
      "主成分个数41: 错误率0.026800\n",
      "主成分个数42: 错误率0.027200\n",
      "主成分个数43: 错误率0.027700\n",
      "主成分个数44: 错误率0.028000\n",
      "主成分个数45: 错误率0.027300\n",
      "主成分个数46: 错误率0.026200\n",
      "主成分个数47: 错误率0.027100\n",
      "主成分个数48: 错误率0.028700\n",
      "主成分个数49: 错误率0.028300\n",
      "主成分个数50: 错误率0.028500\n",
      "主成分个数51: 错误率0.027700\n",
      "主成分个数52: 错误率0.029200\n",
      "主成分个数53: 错误率0.030900\n",
      "主成分个数54: 错误率0.028700\n",
      "主成分个数55: 错误率0.030400\n",
      "主成分个数56: 错误率0.029500\n",
      "主成分个数57: 错误率0.029700\n",
      "主成分个数58: 错误率0.031300\n"
     ]
    }
   ],
   "source": [
    "#在34-59间找到最优个数\n",
    "for n in range(34,59):\n",
    "    pca = PCA(n_components = n)\n",
    "    pca.fit(trainx)\n",
    "    x_train_new = pca.transform(trainx)\n",
    "    x_test_new = pca.transform(testx)\n",
    "    x_train_class_new = []\n",
    "    for i in range(10):\n",
    "        x_train_class_new.append(x_train_new[trainy==i])\n",
    "    #对每个类别进行GMM建模\n",
    "    model = []\n",
    "    for x in x_train_class_new:\n",
    "        gmm = GaussianMixture(n_components = 5, random_state = 0, max_iter = 500)\n",
    "        gmm.fit(x)\n",
    "        model.append(gmm)\n",
    "    #计算log(density)\n",
    "    log_density = []\n",
    "    for GMM in model:\n",
    "        log_density.append(GMM.score_samples(x_test_new))\n",
    "    log_density = np.array(log_density)\n",
    "    #计算log_p_hat\n",
    "    log_P_hat = []\n",
    "    for i in range(10):\n",
    "        log_P_hat.append(np.log(class_prs[i])+log_density[i])\n",
    "    log_P_hat = np.array(log_P_hat)\n",
    "    count_err = 0\n",
    "    for i in range(testy.shape[0]):\n",
    "        if(log_P_hat[:,i].argmax() != testy[i]):\n",
    "            count_err += 1\n",
    "    error = count_err / testy.shape[0]\n",
    "    print(\"主成分个数%d:\"%n,\"错误率%f\"%error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
